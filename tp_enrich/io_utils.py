"""\nI/O utilities for reading and writing CSV files\n"""\nimport pandas as pd\nfrom typing import Dict, List, Optional\nfrom .logging_utils import setup_logger\nlogger = setup_logger(__name__)\ndef map_display_name_column(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Robustly map display name column to raw_display_name\n    Handles various column naming conventions:\n    - consumer.displayName (Apify Trustpilot scraper)\n    - consumer.display_name\n    - displayName\n    - display_name\n    Args:\n        df: DataFrame with original columns (already normalized to lowercase)\n    Returns:\n        DataFrame with raw_display_name column added\n    \"\"\"\n    # Create lowercase mapping (columns are already lowercase from load_input_csv)\n    lower_map = {col.lower(): col for col in df.columns}\n    # Priority list for display name columns (all lowercase since columns are normalized)\n    candidate_keys = [\n        \"consumer.displayname\",\n        \"consumer.display_name\",\n        \"displayname\",\n        \"display_name\",\n    ]\n    # Find first matching column\n    display_col = None\n    for candidate in candidate_keys:\n        if candidate in lower_map:\n            display_col = lower_map[candidate]\n            break\n    # Map to raw_display_name\n    if display_col:\n        df[\"raw_display_name\"] = df[display_col].astype(\"string\").fillna(\"\").str.strip()\n        # Debug logging\n        sample_values = df[\"raw_display_name\"].head(5).tolist()\n        logger.info(f\"✓ Using display name column '{display_col}'\")\n        logger.info(f\"  Sample values: {sample_values}\")\n    else:\n        # No display name column found\n        df[\"raw_display_name\"] = pd.NA\n        logger.warning(f\"✗ No display name column found in: {list(df.columns)}\")\n        logger.warning(f\"  Looked for: {candidate_keys}\")\n    return df\ndef map_review_date_column(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Map review date column to review_date\n    Handles various date column naming conventions:\n    - dates.experiencedDate (Apify Trustpilot scraper)\n    - dates.experienceddate (normalized)\n    - date\n    - review_date\n    Args:\n        df: DataFrame with original columns (already normalized to lowercase)\n    Returns:\n        DataFrame with review_date column added\n    \"\"\"\n    # Create lowercase mapping (columns are already lowercase from load_input_csv)\n    lower_map = {col.lower(): col for col in df.columns}\n    # Priority list for date columns (all lowercase since columns are normalized)\n    candidate_keys = [\n        \"dates.experienceddate\",\n        \"dates.experienced_date\",\n        \"review_date\",\n        \"date\",\n    ]\n    # Find first matching column\n    date_col = None\n    for candidate in candidate_keys:\n        if candidate in lower_map:\n            date_col = lower_map[candidate]\n            break\n    # Map to review_date\n    if date_col:\n        df[\"review_date\"] = df[date_col]\n        logger.info(f\"✓ Using date column '{date_col}' for review_date\")\n    else:\n        # No date column found\n        df[\"review_date\"] = pd.NA\n        logger.warning(f\"✗ No date column found in: {list(df.columns)}\")\n        logger.warning(f\"  Looked for: {candidate_keys}\")\n    return df\ndef load_input_csv(filepath: str) -> pd.DataFrame:\n    \"\"\"\n    Load and normalize input Trustpilot CSV\n    Args:\n        filepath: Path to input CSV\n    Returns:\n        DataFrame with normalized column names and raw_display_name mapped\n    \"\"\"\n    logger.info(f\"Loading input CSV from: {filepath}\")\n    df = pd.read_csv(filepath)\n    # Store original column names for debugging\n    original_columns = list(df.columns)\n    # Normalize column names to lowercase with underscores\n    df.columns = df.columns.str.lower().str.replace(' ', '_').str.replace('-', '_')\n    logger.info(f\"Loaded {len(df)} rows\")\n    logger.info(f\"  Original columns: {original_columns}\")\n    logger.info(f\"  Normalized columns: {list(df.columns)}\")\n    # Map display name column to raw_display_name\n    df = map_display_name_column(df)\n    # Map review date column\n    df = map_review_date_column(df)\n    return df\ndef write_output_csv(df, output_path: str, *args, **kwargs):\n    \"\"\"\n    Write enriched CSV reliably.\n    IMPORTANT:\n    Some callers pass (df, output_path, logger) or other extra args.\n    We accept *args/**kwargs to stay compatible and avoid 500s.\n    - Never silently drops enrichment columns\n    - Ensures expected enrichment columns exist (creates them if missing)\n    - Writes expected columns first, then any extra columns that may exist\n    \"\"\"\n    expected_cols = [\n        \"consumer.displayname\",\n        \"date\",\n        \"raw_display_name\",\n        \"review_date\",\n        \"row_id\",\n        \"run_id\",\n        \"name_classification\",\n        \"company_search_name\",\n        \"company_normalized_key\",\n        \"company_domain\",\n        \"domain_confidence\",\n        \"primary_phone\",\n        \"primary_phone_display\",\n        \"primary_phone_source\",\n        \"primary_phone_confidence\",\n        \"primary_email\",\n        \"primary_email_type\",\n        \"primary_email_source\",\n        \"primary_email_confidence\",\n        \"business_address\",\n        \"business_city\",\n        \"business_state_region\",\n        \"business_postal_code\",\n        \"business_country\",\n        \"oc_company_name\",\n        \"oc_jurisdiction\",\n        \"oc_company_number\",\n        \"oc_incorporation_date\",\n        \"oc_match_confidence\",\n        \"overall_lead_confidence\",\n        \"enrichment_status\",\n        \"enrichment_notes\",\n        \"all_phones_json\",\n        \"generic_emails_json\",\n        \"person_emails_json\",\n        \"catchall_emails_json\",\n        # Phase 2 Contact Data Fields (HOTFIX v2)\n        \"phase2_bbb_phone\",\n        \"phase2_bbb_email\",\n        \"phase2_bbb_website\",\n        \"phase2_bbb_names\",\n        \"phase2_yp_phone\",\n        \"phase2_yp_email\",\n        \"phase2_yp_website\",\n        \"phase2_yp_names\",\n        \"source_platform\",\n    ]\n    # Ensure expected columns exist\n    for col in expected_cols:\n        if col not in df.columns:\n            df[col] = None\n    # Keep expected first, then extras\n    extras = [c for c in df.columns.tolist() if c not in expected_cols]\n    final_cols = expected_cols + extras\n    # Sanity log\n    try:\n        phones = int(df[\"primary_phone\"].notna().sum())\n        emails = int(df[\"primary_email\"].notna().sum())\n        logger.info(f\"Export sanity: rows={len(df)} phones_nonnull={phones} emails_nonnull={emails}\")\n    except Exception:\n        logger.info(f\"Export sanity: rows={len(df)} (could not compute phone/email counts)\")\n    logger.info(f\"Writing output CSV to: {output_path}\")\n    logger.info(f\"Final columns count: {len(final_cols)}\")\n    for c in df.columns:\n        if df[c].dtype == object:\n            df[c] = (\n                df[c]\n                .astype(str)\n                .str.replace(r\"[\\u0000-\\u001F\\u007F]\", \"\", regex=True)  # control chars\n                .str.replace(\"\\u00A0\", \" \", regex=False)                # nbsp\n            )\n    # write with explicit utf-8\n    df.to_csv(output_path, index=False, columns=final_cols, encoding=\"utf-8\")\n    logger.info(f\"Successfully wrote {len(df)} rows to {output_path}\")\ndef get_output_schema() -> List[str]:\n    \"\"\"\n    Returns the exact output schema as defined in Section M\n    Returns:\n        List of column names in exact order\n    \"\"\"\n    return [\n        'row_id',\n        'run_id',\n        'source_platform',\n        'source_lender_name',\n        'source_review_url',\n        'review_date',\n        'review_rating',\n        'raw_display_name',\n        'name_classification',\n        'company_search_name',\n        'company_normalized_key',\n        'company_domain',\n        'domain_confidence',\n        'primary_phone',\n        'primary_phone_display',\n        'primary_phone_source',\n        'primary_phone_confidence',\n        'primary_email',\n        'primary_email_type',\n        'primary_email_source',\n        'primary_email_confidence',\n        'business_address',\n        'business_city',\n        'business_state_region',\n        'business_postal_code',\n        'business_country',\n        'oc_company_name',\n        'oc_jurisdiction',\n        'oc_company_number',\n        'oc_incorporation_date',\n        'oc_match_confidence',\n        'oc_status',\n        'overall_lead_confidence',\n        'enrichment_status',\n        'enrichment_notes',\n        'all_phones_json',\n        'generic_emails_json',\n        'person_emails_json',\n        'catchall_emails_json',\n        'email_providers_tried',\n        'email_provider_errors_json',\n        'email_waterfall_winner',\n        'phase2_bbb_link',\n        'phase2_bbb_names_json',\n        'phase2_yp_link',\n        'phase2_yp_phone',\n        'phase2_yp_names_json',\n        'phase2_oc_link',\n        'phase2_oc_company_number',\n        'phase2_oc_status',\n        # Phase 2 Contact Data Extraction Fields (HOTFIX v2)\n        'phase2_bbb_phone',\n        'phase2_bbb_email',\n        'phase2_bbb_website',\n        'phase2_bbb_names',\n        'phase2_yp_phone',\n        'phase2_yp_email',\n        'phase2_yp_website',\n        'phase2_yp_names',\n        'phase2_notes',\n        'bbb_url',\n        'yellowpages_url',\n        'yelp_url',\n    ]\n